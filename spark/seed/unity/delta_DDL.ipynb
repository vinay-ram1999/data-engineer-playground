{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97346e7",
   "metadata": {},
   "source": [
    "## **Work In Progress**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12c0e9",
   "metadata": {},
   "source": [
    "**Note:** This is a DDL notebook. Run this only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c77d34-e043-4381-83e6-993b70310013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "io.unitycatalog#unitycatalog-spark_2.12 added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "org.slf4j#slf4j-simple added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f34136f3-cc03-4398-9f60-9ef0398a767f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.3.1 in central\n",
      "\tfound io.delta#delta-storage;3.3.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound io.unitycatalog#unitycatalog-spark_2.12;0.2.1 in central\n",
      "\tfound io.unitycatalog#unitycatalog-client;0.2.1 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.13 in central\n",
      "\tfound org.apache.logging.log4j#log4j-slf4j2-impl;2.23.1 in central\n",
      "\tfound org.apache.logging.log4j#log4j-api;2.23.1 in central\n",
      "\tfound org.apache.logging.log4j#log4j-core;2.23.1 in central\n",
      "\tfound com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.17.0 in central\n",
      "\tfound org.openapitools#jackson-databind-nullable;0.2.6 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.15.0 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.15.0 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.15.0 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.0 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-xml;2.15.0 in central\n",
      "\tfound org.codehaus.woodstox#stax2-api;4.2.1 in central\n",
      "\tfound com.fasterxml.woodstox#woodstox-core;6.5.1 in central\n",
      "\tfound org.antlr#antlr4;4.9.3 in central\n",
      "\tfound org.antlr#antlr-runtime;3.5.2 in central\n",
      "\tfound org.antlr#ST4;4.3.1 in central\n",
      "\tfound org.abego.treelayout#org.abego.treelayout.core;1.0.3 in central\n",
      "\tfound org.glassfish#javax.json;1.0.4 in central\n",
      "\tfound com.ibm.icu#icu4j;69.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.4.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.4.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.4 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.8.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.29.52 in central\n",
      "\tfound org.slf4j#slf4j-simple;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.365 in central\n",
      ":: resolution report :: resolve 738ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.365 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.15.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.15.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.15.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-xml;2.15.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.17.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.0 from central in [default]\n",
      "\tcom.fasterxml.woodstox#woodstox-core;6.5.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.ibm.icu#icu4j;69.1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.3.1 from central in [default]\n",
      "\tio.delta#delta-storage;3.3.1 from central in [default]\n",
      "\tio.unitycatalog#unitycatalog-client;0.2.1 from central in [default]\n",
      "\tio.unitycatalog#unitycatalog-spark_2.12;0.2.1 from central in [default]\n",
      "\torg.abego.treelayout#org.abego.treelayout.core;1.0.3 from central in [default]\n",
      "\torg.antlr#ST4;4.3.1 from central in [default]\n",
      "\torg.antlr#antlr-runtime;3.5.2 from central in [default]\n",
      "\torg.antlr#antlr4;4.9.3 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.4.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.4.0 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.8.1 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-api;2.23.1 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-core;2.23.1 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-slf4j2-impl;2.23.1 from central in [default]\n",
      "\torg.codehaus.woodstox#stax2-api;4.2.1 from central in [default]\n",
      "\torg.glassfish#javax.json;1.0.4 from central in [default]\n",
      "\torg.openapitools#jackson-databind-nullable;0.2.6 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.13 from central in [default]\n",
      "\torg.slf4j#slf4j-simple;2.0.7 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.4 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.29.52 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;2.0.9 by [org.slf4j#slf4j-api;2.0.13] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.17.0 by [com.fasterxml.jackson.core#jackson-annotations;2.15.0] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.17.0 by [com.fasterxml.jackson.core#jackson-core;2.15.0] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.17.0 by [com.fasterxml.jackson.core#jackson-databind;2.15.0] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.14.0-rc2 by [com.fasterxml.jackson.core#jackson-databind;2.15.0] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.13] in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 by [org.slf4j#slf4j-api;2.0.13] in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.365] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   44  |   0   |   0   |   8   ||   36  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f34136f3-cc03-4398-9f60-9ef0398a767f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 36 already retrieved (0kB/12ms)\n",
      "25/05/02 04:43:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 3.5.5 is up and running!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from seed.unity import conf\n",
    "\n",
    "# WARNING: The 'spark.sql.catalog.unity.token' should always match the value in ./unity/conf/token.txt  \n",
    "# this changes every time the container is restarted\n",
    "\n",
    "spark: SparkSession = SparkSession.builder.config(conf=conf)\\\n",
    "                        .config('spark.sql.catalog.unity.token', 'eyJraWQiOiI0MjA5OThiMTc3ZWUzNzdmZjliZjRlMTA1ZDg1ZWEwOTNkMjNmN2I3MWQ4YjNjYWVmYjdiODU1ODc1ZmVhZDQzIiwiYWxnIjoiUlM1MTIiLCJ0eXAiOiJKV1QifQ.eyJzdWIiOiJhZG1pbiIsImlzcyI6ImludGVybmFsIiwiaWF0IjoxNzQ2MTU4MDE2LCJqdGkiOiIzOWE1MmRjZS1kMzc1LTQ1MWQtODAwZS05M2MwYTg1Y2E1NjEiLCJ0eXBlIjoiU0VSVklDRSJ9.Jl7O9_d85y8NzuQX9XPw4WcbACSpeAPahRiKIt06M2G8FSZF4j2w1qbLlqLn5DLjGFVzldlT08vN4s3sMhAboDWGvxu1PqEieD7x1WJlwpoAw3Ar7CHVnTYXm0UitSacIccssSz1rigKnJn8YX-oKcl-q6RXAKoYaA4c35fC9mU5lrPimYBGjnlA2kTFAm3596BvqOHGsTnv5Pf3SG0kmeYxz1sNo-P2FlLbQJoecLyfcIDEnTNeJ29fyc7ieXxd92uYbeq-AqoO-hp0lwnf95bDeTF_sl5TLnUO3Gp-WEw4XjeXyV38Mz6Mu7kNLLNm57bQ_KS5TpUWZT278SO8nQ')\\\n",
    "                        .getOrCreate()\n",
    "\n",
    "print(f\"Spark {spark.version} is up and running!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31b0a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|spark_catalog|\n",
      "|        unity|\n",
      "+-------------+\n",
      "\n",
      "+---------+-----------------+-----------+\n",
      "|namespace|        tableName|isTemporary|\n",
      "+---------+-----------------+-----------+\n",
      "|  default|        marksheet|      false|\n",
      "|  default|marksheet_uniform|      false|\n",
      "|  default|          numbers|      false|\n",
      "|  default|             test|      false|\n",
      "|  default|   user_countries|      false|\n",
      "+---------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN unity.default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8d9625",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DELTA_PATH_DOES_NOT_EXIST] file:/home/unitycatalog/etc/data/external/unity/default/tables/numbers doesn't exist, or is not a Delta table.;\nDescribeRelation true, [col_name#39, data_type#40, comment#41]\n+- ResolvedTable io.unitycatalog.spark.UCSingleCatalog@54121032, default.numbers, DeltaTableV2(org.apache.spark.sql.SparkSession@2708136c,file:/home/unitycatalog/etc/data/external/unity/default/tables/numbers,Some(CatalogTable(\nCatalog: unity\nDatabase: default\nTable: numbers\nCreated Time: Wed Jul 17 18:40:05 UTC 2024\nLast Access: UNKNOWN\nCreated By: Spark \nType: EXTERNAL\nProvider: DELTA\nLocation: file:///home/unitycatalog/etc/data/external/unity/default/tables/numbers\nStorage Properties: [key1=value1, key2=value2]\nSchema: root\n |-- as_int: integer (nullable = false)\n |-- as_double: double (nullable = false)\n)),Some(default.numbers),None,Map())\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDESC EXTENDED unity.default.numbers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/pyspark/sql/session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [DELTA_PATH_DOES_NOT_EXIST] file:/home/unitycatalog/etc/data/external/unity/default/tables/numbers doesn't exist, or is not a Delta table.;\nDescribeRelation true, [col_name#39, data_type#40, comment#41]\n+- ResolvedTable io.unitycatalog.spark.UCSingleCatalog@54121032, default.numbers, DeltaTableV2(org.apache.spark.sql.SparkSession@2708136c,file:/home/unitycatalog/etc/data/external/unity/default/tables/numbers,Some(CatalogTable(\nCatalog: unity\nDatabase: default\nTable: numbers\nCreated Time: Wed Jul 17 18:40:05 UTC 2024\nLast Access: UNKNOWN\nCreated By: Spark \nType: EXTERNAL\nProvider: DELTA\nLocation: file:///home/unitycatalog/etc/data/external/unity/default/tables/numbers\nStorage Properties: [key1=value1, key2=value2]\nSchema: root\n |-- as_int: integer (nullable = false)\n |-- as_double: double (nullable = false)\n)),Some(default.numbers),None,Map())\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESC EXTENDED unity.default.numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fce10",
   "metadata": {},
   "source": [
    "- The `spark` instance is trying to access data located in the `unity` container file system which is causing issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659b6d26",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DELTA_TABLE_NOT_FOUND] Delta table `default`.`numbers` doesn't exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT * FROM unity.default.numbers LIMIT 5;\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/pyspark/sql/session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [DELTA_TABLE_NOT_FOUND] Delta table `default`.`numbers` doesn't exist."
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM unity.default.numbers LIMIT 5;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3143b4-0a1c-4905-ad08-fc20f35eed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 04:46:45 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------+--------+---------+---------+\n",
      "|   FL_DATE|DEP_DELAY|ARR_DELAY|AIR_TIME|DISTANCE| DEP_TIME| ARR_TIME|\n",
      "+----------+---------+---------+--------+--------+---------+---------+\n",
      "|2006-01-01|        5|       19|     350|    2475| 9.083333|12.483334|\n",
      "|2006-01-02|      167|      216|     343|    2475|11.783334|15.766666|\n",
      "|2006-01-03|       -7|       -2|     344|    2475| 8.883333|12.133333|\n",
      "|2006-01-04|       -5|      -13|     331|    2475| 8.916667|    11.95|\n",
      "|2006-01-05|       -3|      -17|     321|    2475|     8.95|11.883333|\n",
      "+----------+---------+---------+--------+--------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- DEP_DELAY: short (nullable = true)\n",
      " |-- ARR_DELAY: short (nullable = true)\n",
      " |-- AIR_TIME: short (nullable = true)\n",
      " |-- DISTANCE: short (nullable = true)\n",
      " |-- DEP_TIME: float (nullable = true)\n",
      " |-- ARR_TIME: float (nullable = true)\n",
      "\n",
      "+----------+----------+--------+\n",
      "|  min_date|  max_date|num_rows|\n",
      "+----------+----------+--------+\n",
      "|2006-01-01|2006-02-28| 1000000|\n",
      "+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read flights data from parquet file\n",
    "\n",
    "df = spark.read.parquet(\"s3a://seed/flights-1m.parquet\")\n",
    "df.show(5)\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.createOrReplaceTempView(\"raw_flights\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        MIN(FL_DATE) AS min_date,\n",
    "        MAX(FL_DATE) AS max_date,\n",
    "        COUNT(*) AS num_rows\n",
    "    FROM raw_flights;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4987e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------+\n",
      "|namespace|        tableName|isTemporary|\n",
      "+---------+-----------------+-----------+\n",
      "|  default|        marksheet|      false|\n",
      "|  default|marksheet_uniform|      false|\n",
      "|  default|          numbers|      false|\n",
      "|  default|             test|      false|\n",
      "|  default|   user_countries|      false|\n",
      "+---------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE EXTERNAL TABLE IF NOT EXISTS unity.default.test (name STRING) USING delta LOCATION 's3a://unity/test'\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES FROM unity.default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2836c9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DELTA_PATH_DOES_NOT_EXIST] file:/home/unitycatalog/s3a:/unity/test doesn't exist, or is not a Delta table.;\nDescribeRelation true, [col_name#147, data_type#148, comment#149]\n+- ResolvedTable io.unitycatalog.spark.UCSingleCatalog@54121032, default.test, DeltaTableV2(org.apache.spark.sql.SparkSession@2708136c,file:/home/unitycatalog/s3a:/unity/test,Some(CatalogTable(\nCatalog: unity\nDatabase: default\nTable: test\nCreated Time: Fri May 02 04:37:35 UTC 2025\nLast Access: UNKNOWN\nCreated By: Spark \nType: EXTERNAL\nProvider: DELTA\nLocation: file:///home/unitycatalog/s3a:/unity/test)),Some(default.test),None,Map())\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDESC EXTENDED unity.default.test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/pyspark/sql/session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~opt/bitnami/python/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [DELTA_PATH_DOES_NOT_EXIST] file:/home/unitycatalog/s3a:/unity/test doesn't exist, or is not a Delta table.;\nDescribeRelation true, [col_name#147, data_type#148, comment#149]\n+- ResolvedTable io.unitycatalog.spark.UCSingleCatalog@54121032, default.test, DeltaTableV2(org.apache.spark.sql.SparkSession@2708136c,file:/home/unitycatalog/s3a:/unity/test,Some(CatalogTable(\nCatalog: unity\nDatabase: default\nTable: test\nCreated Time: Fri May 02 04:37:35 UTC 2025\nLast Access: UNKNOWN\nCreated By: Spark \nType: EXTERNAL\nProvider: DELTA\nLocation: file:///home/unitycatalog/s3a:/unity/test)),Some(default.test),None,Map())\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESC EXTENDED unity.default.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d65e79",
   "metadata": {},
   "source": [
    "- It is converting S3 object path to absolute system path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf9c4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
